<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>The AsyncResult object &mdash; IPython 2.0.0-dev documentation</title>
    
    <link rel="stylesheet" href="../_static/default.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2.0.0-dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="IPython 2.0.0-dev documentation" href="../index.html" />
    <link rel="up" title="Using IPython for parallel computing" href="index.html" />
    <link rel="next" title="Using MPI with IPython" href="parallel_mpi.html" />
    <link rel="prev" title="The IPython task interface" href="parallel_task.html" /> 
  </head>
  <body>

<div style="background-color: white; text-align: left; padding: 10px 10px 15px 15px">
<a href="http://ipython.org/"><img src="../_static/logo.png" border="0" alt="IPython Documentation"/></a>
</div>

    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="parallel_mpi.html" title="Using MPI with IPython"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="parallel_task.html" title="The IPython task interface"
             accesskey="P">previous</a> |</li>
        <li><a href="http://ipython.org">home</a>|&nbsp;</li>
        <li><a href="../search.html">search</a>|&nbsp;</li>
       <li><a href="../index.html">documentation </a> &raquo;</li>

          <li><a href="index.html" accesskey="U">Using IPython for parallel computing</a> &raquo;</li> 
      </ul>
    </div>

      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">The AsyncResult object</a><ul>
<li><a class="reference internal" href="#beyond-multiprocessing-s-asyncresult">Beyond multiprocessing&#8217;s AsyncResult</a><ul>
<li><a class="reference internal" href="#get-dict">get_dict</a></li>
</ul>
</li>
<li><a class="reference internal" href="#metadata">Metadata</a><ul>
<li><a class="reference internal" href="#timing">Timing</a></li>
</ul>
</li>
<li><a class="reference internal" href="#map-results-are-iterable">Map results are iterable!</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="parallel_task.html"
                        title="previous chapter">The IPython task interface</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="parallel_mpi.html"
                        title="next chapter">Using MPI with IPython</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/parallel/asyncresult.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <blockquote>
<div><div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This documentation is for a development version of IPython. There may be
significant differences from the latest stable release (1.2.1).</p>
</div>
</div></blockquote>
<div class="section" id="the-asyncresult-object">
<span id="parallel-asyncresult"></span><h1>The AsyncResult object<a class="headerlink" href="#the-asyncresult-object" title="Permalink to this headline">¶</a></h1>
<p>In non-blocking mode, <tt class="xref py py-meth docutils literal"><span class="pre">apply()</span></tt> submits the command to be executed and
then returns a <a class="reference internal" href="parallel_details.html#AsyncResult" title="AsyncResult"><tt class="xref py py-class docutils literal"><span class="pre">AsyncResult</span></tt></a> object immediately. The
AsyncResult object gives you a way of getting a result at a later
time through its <tt class="xref py py-meth docutils literal"><span class="pre">get()</span></tt> method, but it also collects metadata
on execution.</p>
<div class="section" id="beyond-multiprocessing-s-asyncresult">
<h2>Beyond multiprocessing&#8217;s AsyncResult<a class="headerlink" href="#beyond-multiprocessing-s-asyncresult" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The <a class="reference internal" href="parallel_details.html#AsyncResult" title="AsyncResult"><tt class="xref py py-class docutils literal"><span class="pre">AsyncResult</span></tt></a> object provides a superset of the interface in
<a class="reference external" href="http://docs.python.org/2/library/multiprocessing.html#multiprocessing.pool.AsyncResult" title="(in Python v2.7)"><tt class="xref py py-class docutils literal"><span class="pre">multiprocessing.pool.AsyncResult</span></tt></a>.  See the
<a class="reference external" href="http://docs.python.org/library/multiprocessing#multiprocessing.pool.AsyncResult">official Python documentation</a>
for more on the basics of this interface.</p>
</div>
<p>Our AsyncResult objects add a number of convenient features for working with
parallel results, beyond what is provided by the original AsyncResult.</p>
<div class="section" id="get-dict">
<h3>get_dict<a class="headerlink" href="#get-dict" title="Permalink to this headline">¶</a></h3>
<p>First, is <tt class="xref py py-meth docutils literal"><span class="pre">AsyncResult.get_dict()</span></tt>, which pulls results as a dictionary
keyed by engine_id, rather than a flat list.  This is useful for quickly
coordinating or distributing information about all of the engines.</p>
<p>As an example, here is a quick call that gives every engine a dict showing
the PID of every other engine:</p>
<div class="highlight-ipython"><div class="highlight"><pre><span class="gp">In [10]: </span><span class="n">ar</span> <span class="o">=</span> <span class="n">rc</span><span class="p">[:]</span><span class="o">.</span><span class="n">apply_async</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">)</span>
<span class="gp">In [11]: </span><span class="n">pids</span> <span class="o">=</span> <span class="n">ar</span><span class="o">.</span><span class="n">get_dict</span><span class="p">()</span>
<span class="gp">In [12]: </span><span class="n">rc</span><span class="p">[:][</span><span class="s">&#39;pid_map&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pids</span>
</pre></div>
</div>
<p>This trick is particularly useful when setting up inter-engine communication,
as in IPython&#8217;s <tt class="file docutils literal"><span class="pre">examples/parallel/interengine</span></tt> examples.</p>
</div>
</div>
<div class="section" id="metadata">
<h2>Metadata<a class="headerlink" href="#metadata" title="Permalink to this headline">¶</a></h2>
<p>IPython.parallel tracks some metadata about the tasks, which is stored
in the <tt class="xref py py-attr docutils literal"><span class="pre">Client.metadata</span></tt> dict.  The AsyncResult object gives you an
interface for this information as well, including timestamps stdout/err,
and engine IDs.</p>
<div class="section" id="timing">
<h3>Timing<a class="headerlink" href="#timing" title="Permalink to this headline">¶</a></h3>
<p>IPython tracks various timestamps as <tt class="xref py py-class docutils literal"><span class="pre">datetime</span></tt> objects,
and the AsyncResult object has a few properties that turn these into useful
times (in seconds as floats).</p>
<p>For use while the tasks are still pending:</p>
<ul>
<li><p class="first"><tt class="xref py py-attr docutils literal"><span class="pre">ar.elapsed</span></tt> is just the elapsed seconds since submission, for use
before the AsyncResult is complete.</p>
</li>
<li><p class="first"><tt class="xref py py-attr docutils literal"><span class="pre">ar.progress</span></tt> is the number of tasks that have completed.  Fractional progress
would be:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="mf">1.0</span> <span class="o">*</span> <span class="n">ar</span><span class="o">.</span><span class="n">progress</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ar</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p class="first"><tt class="xref py py-meth docutils literal"><span class="pre">AsyncResult.wait_interactive()</span></tt> will wait for the result to finish, but
print out status updates on progress and elapsed time while it waits.</p>
</li>
</ul>
<p>For use after the tasks are done:</p>
<ul class="simple">
<li><tt class="xref py py-attr docutils literal"><span class="pre">ar.serial_time</span></tt> is the sum of the computation time of all of the tasks
done in parallel.</li>
<li><tt class="xref py py-attr docutils literal"><span class="pre">ar.wall_time</span></tt> is the time between the first task submitted and last result
received.  This is the actual cost of computation, including IPython overhead.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">wall_time is only precise if the Client is waiting for results when
the task finished, because the <cite>received</cite> timestamp is made when the result is
unpacked by the Client, triggered by the <tt class="xref py py-meth docutils literal"><span class="pre">spin()</span></tt> call. If you
are doing work in the Client, and not waiting/spinning, then <cite>received</cite> might
be artificially high.</p>
</div>
<p>An often interesting metric is the time it actually cost to do the work in parallel
relative to the serial computation, and this can be given simply with</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">speedup</span> <span class="o">=</span> <span class="n">ar</span><span class="o">.</span><span class="n">serial_time</span> <span class="o">/</span> <span class="n">ar</span><span class="o">.</span><span class="n">wall_time</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="map-results-are-iterable">
<h2>Map results are iterable!<a class="headerlink" href="#map-results-are-iterable" title="Permalink to this headline">¶</a></h2>
<p>When an AsyncResult object has multiple results (e.g. the <tt class="xref py py-class docutils literal"><span class="pre">AsyncMapResult</span></tt>
object), you can actually iterate through results themselves, and act on them as they arrive:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">parallel</span>

<span class="c"># create client &amp; view</span>
<span class="n">rc</span> <span class="o">=</span> <span class="n">parallel</span><span class="o">.</span><span class="n">Client</span><span class="p">()</span>
<span class="n">dv</span> <span class="o">=</span> <span class="n">rc</span><span class="p">[:]</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">rc</span><span class="o">.</span><span class="n">load_balanced_view</span><span class="p">()</span>

<span class="c"># scatter &#39;id&#39;, so id=0,1,2 on engines 0,1,2</span>
<span class="n">dv</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="n">rc</span><span class="o">.</span><span class="n">ids</span><span class="p">,</span> <span class="n">flatten</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;Engine IDs: &quot;</span><span class="p">,</span> <span class="n">dv</span><span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">])</span>

<span class="c"># create a Reference to `id`. This will be a different value on each engine</span>
<span class="n">ref</span> <span class="o">=</span> <span class="n">parallel</span><span class="o">.</span><span class="n">Reference</span><span class="p">(</span><span class="s">&#39;id&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;sleeping for `id` seconds on each engine&quot;</span><span class="p">)</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">ar</span> <span class="o">=</span> <span class="n">dv</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">,</span> <span class="n">ref</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ar</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;</span><span class="si">%i</span><span class="s">: </span><span class="si">%.3f</span><span class="s">&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">tic</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">sleep_here</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">time</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">id</span><span class="p">,</span><span class="n">t</span>

<span class="c"># one call per task</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;running with one call per task&quot;</span><span class="p">)</span>
<span class="n">amr</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sleep_here</span><span class="p">,</span> <span class="p">[</span><span class="o">.</span><span class="mo">01</span><span class="o">*</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)])</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">amr</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;task </span><span class="si">%i</span><span class="s"> on engine </span><span class="si">%i</span><span class="s">: </span><span class="si">%.3f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">tic</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;running with four calls per task&quot;</span><span class="p">)</span>
<span class="c"># with chunksize, we can have four calls per task</span>
<span class="n">amr</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sleep_here</span><span class="p">,</span> <span class="p">[</span><span class="o">.</span><span class="mo">01</span><span class="o">*</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)],</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">amr</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;task </span><span class="si">%i</span><span class="s"> on engine </span><span class="si">%i</span><span class="s">: </span><span class="si">%.3f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">tic</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;running with two calls per task, with unordered results&quot;</span><span class="p">)</span>
<span class="c"># We can even iterate through faster results first, with ordered=False</span>
<span class="n">amr</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sleep_here</span><span class="p">,</span> <span class="p">[</span><span class="o">.</span><span class="mo">01</span><span class="o">*</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="n">ordered</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">tic</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">amr</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;slept </span><span class="si">%.2f</span><span class="s">s on engine </span><span class="si">%i</span><span class="s">: </span><span class="si">%.3f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span><span class="o">-</span><span class="n">tic</span><span class="p">))</span>
</pre></div>
</div>
<p>That is to say, if you treat an AsyncMapResult as if it were a list of your actual
results, it should behave as you would expect, with the only difference being
that you can start iterating through the results before they have even been computed.</p>
<p>This lets you do a dumb version of map/reduce with the builtin Python functions,
and the only difference between doing this locally and doing it remotely in parallel
is using the asynchronous view.map instead of the builtin map.</p>
<p>Here is a simple one-line RMS (root-mean-square) implemented with Python&#8217;s builtin map/reduce.</p>
<div class="highlight-ipython"><div class="highlight"><pre><span class="gp">In [38]: </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>

<span class="gp">In [39]: </span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>

<span class="gp">In [40]: </span><span class="n">add</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">:</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span>

<span class="gp">In [41]: </span><span class="n">sq</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span>

<span class="gp">In [42]: </span><span class="n">sqrt</span><span class="p">(</span><span class="nb">reduce</span><span class="p">(</span><span class="n">add</span><span class="p">,</span> <span class="nb">map</span><span class="p">(</span><span class="n">sq</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="gh">Out[42]: </span><span class="go">58.028845747399714</span>

<span class="gp">In [43]: </span><span class="n">sqrt</span><span class="p">(</span><span class="nb">reduce</span><span class="p">(</span><span class="n">add</span><span class="p">,</span> <span class="n">view</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sq</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="gh">Out[43]: </span><span class="go">58.028845747399714</span>
</pre></div>
</div>
<p>To break that down:</p>
<ol class="arabic simple">
<li><tt class="docutils literal"><span class="pre">map(sq,</span> <span class="pre">X)</span></tt> Compute the square of each element in the list (locally, or in parallel)</li>
<li><tt class="docutils literal"><span class="pre">reduce(add,</span> <span class="pre">sqX)</span> <span class="pre">/</span> <span class="pre">len(X)</span></tt> compute the mean by summing over the list (or AsyncMapResult)
and dividing by the size</li>
<li>take the square root of the resulting number</li>
</ol>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p>When AsyncResult or the AsyncMapResult don&#8217;t provide what you need (for instance,
handling individual results as they arrive, but with metadata), you can always
just split the original result&#8217;s <tt class="docutils literal"><span class="pre">msg_ids</span></tt> attribute, and handle them as you like.</p>
<p class="last">For an example of this, see <tt class="file docutils literal"><span class="pre">examples/parallel/customresult.py</span></tt></p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="parallel_mpi.html" title="Using MPI with IPython"
             >next</a> |</li>
        <li class="right" >
          <a href="parallel_task.html" title="The IPython task interface"
             >previous</a> |</li>
        <li><a href="http://ipython.org">home</a>|&nbsp;</li>
        <li><a href="../search.html">search</a>|&nbsp;</li>
       <li><a href="../index.html">documentation </a> &raquo;</li>

          <li><a href="index.html" >Using IPython for parallel computing</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2008, The IPython Development Team.
      Last updated on Apr 01, 2014.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.2.
    </div>
  </body>
</html>